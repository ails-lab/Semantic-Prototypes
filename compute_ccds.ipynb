{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c438e42-d4c4-4909-925b-4af7e01ea0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from copy import copy\n",
    "import random\n",
    "from itertools import groupby\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fb0a4-2e35-4931-962c-5edb782f1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASD:\n",
    "    \n",
    "    def __init__(self, sets=[]):\n",
    "        set_of_sets = []\n",
    "        for s1 in sets:\n",
    "            if not any(s2 > s1 for s2 in sets):\n",
    "                set_of_sets.append(s1)\n",
    "        self.sets = frozenset(frozenset(s) for s in set_of_sets)\n",
    "\n",
    "    def __le__(self, other):\n",
    "        return all(any(s1 <= s2 for s2 in other.sets) for s1 in self.sets)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.sets)\n",
    "\n",
    "    def __and__(self, other):\n",
    "        return ASD(sets=[s1 & s2 for s1, s2 in product(self.sets, other.sets)])\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.sets)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019399e-8d25-4007-b508-5b5adcbd8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(r1, r2):\n",
    "    r1_sim = sum(max(len(s1 & s2)/len(s1 | s2)\n",
    "                     for s2 in r2.sets)\n",
    "                 for s1 in r1.sets)/len(r1)\n",
    "    r2_sim = sum(max(len(s1 & s2)/len(s1 | s2)\n",
    "                     for s1 in r1.sets)\n",
    "                 for s2 in r2.sets)/len(r2)\n",
    "    return (r1_sim + r2_sim)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ad0c6-bca8-4db8-9cb3-925406cb03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ccds(pos_ids, pos_asds, neg_ids, neg_asds):\n",
    "    all_ids = copy(pos_ids)\n",
    "    all_ids.extend(neg_ids)\n",
    "    all_asds = copy(pos_asds)\n",
    "    all_asds.extend(neg_asds)\n",
    "    id_to_asd = dict(zip(all_ids, all_asds))\n",
    "    asd_to_id = dict(zip(all_asds, all_ids))\n",
    "    neg_ids = set(neg_ids)\n",
    "\n",
    "    ccds = []\n",
    "    \n",
    "    for pos_id, pos_asd in tqdm(list(zip(pos_ids, pos_asds))):\n",
    "        description = pos_asd\n",
    "        cluster = {pos_id}\n",
    "\n",
    "        asds_by_sim = sorted([(asd_prime, similarity(description, asd_prime))\n",
    "                              for asd_prime in pos_asds],\n",
    "                             key=lambda x: x[1])\n",
    "\n",
    "        while asds_by_sim:\n",
    "            ncd = description & asds_by_sim.pop()[0]\n",
    "            new_cluster = {asd_to_id[asd_prime]\n",
    "                           for asd_prime in all_asds if ncd <= asd_prime}\n",
    "            ncd_is_dirty = len(new_cluster & neg_ids)\n",
    "            if not ncd_is_dirty:\n",
    "                description = ncd\n",
    "                cluster = new_cluster\n",
    "                asds_by_sim = sorted([(asd_prime, similarity(description, asd_prime))\n",
    "                                      for asd_prime, _ in asds_by_sim],\n",
    "                                     key=lambda x: x[1])\n",
    "\n",
    "        ccds.append({'description': description, 'cluster': cluster})\n",
    "\n",
    "    return ccds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc04040-ff73-4df1-8c50-69167b55ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ccds(ccds):\n",
    "    all_datapoints = set().union(*(ccd['cluster'] for ccd in ccds))\n",
    "    \n",
    "    sorted_ccds = sorted(ccds, key=lambda x: len(x['cluster']), reverse=True)\n",
    "    \n",
    "    selected_ccds = []\n",
    "    covered_datapoints = set()\n",
    "    remaining_ccds = ccds\n",
    "    \n",
    "    while not all_datapoints <= covered_datapoints and remaining_ccds:\n",
    "        remaining_ccds = [ccd for ccd in sorted_ccds if not ccd['cluster'] <= covered_datapoints]\n",
    "        selected_ccd = max(remaining_ccds,\n",
    "                           key=lambda ccd: len(ccd['cluster'] - covered_datapoints))\n",
    "        \n",
    "        selected_ccds.append(selected_ccd)\n",
    "        covered_datapoints.update(selected_ccd['cluster'])\n",
    "       \n",
    "    print(\"Initial number of ccds: \" + str(len(ccds)))\n",
    "    print(\"New number of ccds: \" + str(len(selected_ccds)))\n",
    "    \n",
    "    max_cluster_size = max(len(ccd['cluster']) for ccd in selected_ccds)\n",
    "    min_cluster_size = min(len(ccd['cluster']) for ccd in selected_ccds)\n",
    "    \n",
    "    print(\"Most datapoints in a cluster: \" + str(max_cluster_size))\n",
    "    print(\"Least datapoints in a cluster: \" + str(min_cluster_size))\n",
    "    \n",
    "    return selected_ccds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e250aa46-a931-413a-8c68-cf8cae24ed06",
   "metadata": {},
   "source": [
    "## CUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af81971-97a5-4ed5-a5b7-0b514f6e9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cub_dir = '../CUB/CUB_200_2011/'\n",
    "attributes_dir = os.path.join(cub_dir, 'CUB_200_2011', 'attributes')\n",
    "\n",
    "with open(os.path.join(attributes_dir, 'image_attribute_labels.txt'), 'r') as fp:\n",
    "    image_attribute_labels_strings = list(fp)\n",
    "    def attributes_from_str(s):\n",
    "        attributes = s.strip().split(' ')\n",
    "        return (int(attributes[0]), int(attributes[1]), attributes[2] == '1')\n",
    "    image_attribute_labels = [attributes_from_str(s)\n",
    "                              for s in image_attribute_labels_strings]\n",
    "\n",
    "with open(os.path.join(attributes_dir, 'attributes.txt'), 'r') as fp:\n",
    "    attribute_strings = list(fp)\n",
    "    attributes_by_id = [s.split(' ', 1) for s in attribute_strings]\n",
    "    attributes_by_id = {int(k): v.strip() for k, v in attributes_by_id}\n",
    "\n",
    "with open(os.path.join(cub_dir, 'CUB_200_2011', 'images.txt'), 'r') as fp:\n",
    "    image_ids_strings = list(fp)\n",
    "    image_ids = [s.strip().split(' ') for s in image_ids_strings]\n",
    "    image_id_to_fn = {int(i): s for i, s in image_ids}\n",
    "    # image_fn_to_id = {s: int(i) for i, s in image_ids}\n",
    "\n",
    "with open(os.path.join(cub_dir, 'CUB_200_2011', 'image_class_labels.txt'), 'r') as fp:\n",
    "    image_id_to_class_strings = list(fp)\n",
    "    image_id_to_class = [s.split(' ') for s in image_id_to_class_strings]\n",
    "    image_id_to_class = {int(k): int(v) for k, v in image_id_to_class}\n",
    "    image_ids_by_class = {cl: [x[0] for x in lst]\n",
    "                          for cl, lst in groupby(sorted(image_id_to_class.items(),\n",
    "                                                        key=lambda x: x[1]),\n",
    "                                                 key=lambda x: x[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39562b-02d3-4398-bee7-be0d31e59f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_labels_by_image = groupby(sorted(image_attribute_labels,\n",
    "                                           key=lambda x:x[0]),\n",
    "                                    key=lambda x: x[0])\n",
    "\n",
    "\n",
    "def cub_asd_from_attributes(attributes):\n",
    "    set = []\n",
    "    for _, attribute_id, is_present in attributes:\n",
    "        if is_present:\n",
    "            attribute = attributes_by_id[attribute_id]\n",
    "            set.append(attribute)\n",
    "    return ASD([set])\n",
    "\n",
    "id_to_asd = {k: cub_asd_from_attributes(attributes)\n",
    "             for k, attributes in attribute_labels_by_image}\n",
    "asd_to_id = {asd: id for id, asd in id_to_asd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da384b8-3315-42bd-af0b-e6455e1a6cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = [(6, 7), (23, 25), (47, 180), (60, 64)]\n",
    "ccds = {}\n",
    "\n",
    "for class_pair in classes:\n",
    "    print(class_pair)\n",
    "    ccds[class_pair] = {}\n",
    "    pos_cl, neg_cl = class_pair\n",
    "    \n",
    "    for _ in range(2):\n",
    "        pos_ids = image_ids_by_class[pos_cl]\n",
    "        pos_asds = [id_to_asd[i] for i in pos_ids]\n",
    "        neg_ids = image_ids_by_class[neg_cl]\n",
    "        neg_asds = [id_to_asd[i] for i in neg_ids]\n",
    "        ccds[class_pair][pos_cl] = [\n",
    "            {\n",
    "                'description': ccd['description'].sets,\n",
    "                'cluster': {image_id_to_fn[id] for id in ccd['cluster']}\n",
    "            }\n",
    "            for ccd in filter_ccds(\n",
    "                compute_ccds(pos_ids, pos_asds, neg_ids, neg_asds)\n",
    "            )\n",
    "        ]\n",
    "        pos_cl, neg_cl = neg_cl, pos_cl\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1131f-7b6c-4274-bbac-b5a45794b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('results', 'CUB_ccds.pickle'), 'wb') as fp:\n",
    "    pickle.dump(ccds, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cfd8c-3f23-4136-9e8e-e214cb2263d7",
   "metadata": {},
   "source": [
    "## CLEVR-Hans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987eee5-2039-4e75-ab42-45b2178c2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clevrhans_dir = '../CLEVR-Hans3/'\n",
    "\n",
    "with open('CLEVR-Hans3_attributes.json', 'r') as fp:\n",
    "    clevrhans_attributes = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532c183-6541-4fe1-8257-bb4cf355670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_to_asd = {\n",
    "    fn: ASD([set(obj) for obj in obj_list])\n",
    "    for fn, obj_list in clevrhans_attributes.items()\n",
    "}\n",
    "\n",
    "all_asds = set(fn_to_asd.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cef691-a4d5-44e0-a5f5-d951307cce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccds = {}\n",
    "\n",
    "for cl in [0, 1, 2]:\n",
    "    with open(os.path.join(clevrhans_dir, 'class_{}_positives.txt'.format(cl)), 'r') as fp:\n",
    "        positives = list(fp)\n",
    "    pos_ids = [p.strip() for p in positives]\n",
    "    neg_ids = list(fn_to_asd.keys() - set(pos_ids))\n",
    "    pos_asds = [fn_to_asd[p] for p in pos_ids]\n",
    "    neg_asds = all_asds - set(pos_asds)\n",
    "\n",
    "    ccds[cl] = [\n",
    "        {\n",
    "            'description': ccd['description'].sets,\n",
    "            'cluster': set(ccd['cluster'])\n",
    "        }\n",
    "        for ccd in filter_ccds(\n",
    "            compute_ccds(pos_ids[:80], pos_asds[:80], neg_ids, neg_asds)\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382e828-7772-4de7-9973-9d0cdbbf660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('results', 'CLEVR-Hans3_ccds.pickle'), 'wb') as fp:\n",
    "    pickle.dump(ccds, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f812f-ae9c-400e-a7de-c7d8ed34f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protosem",
   "language": "python",
   "name": "protosem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
